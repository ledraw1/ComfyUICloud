{"last_node_id": 23, "last_link_id": 35, "nodes": [{"id": 6, "type": "EmptyLatentImage", "pos": [100, 358], "size": {"0": 315, "1": 106}, "flags": {}, "order": 0, "mode": 0, "outputs": [{"name": "LATENT", "type": "LATENT", "links": [7], "shape": 3}], "properties": {"Node name for S&R": "EmptyLatentImage"}, "widgets_values": [576, 960, 3]}, {"id": 2, "type": "CLIPSetLastLayer", "pos": [515, 130], "size": {"0": 315, "1": 58}, "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 1}], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [30], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "CLIPSetLastLayer"}, "widgets_values": [-2]}, {"id": 8, "type": "VAELoader", "pos": [157, 540], "size": {"0": 315, "1": 58}, "flags": {}, "order": 1, "mode": 0, "outputs": [{"name": "VAE", "type": "VAE", "links": [10], "shape": 3}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["vae-ft-mse-840000-ema-pruned.safetensors"]}, {"id": 14, "type": "CR Apply LoRA Stack", "pos": [954, 135], "size": {"0": 210, "1": 66}, "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 34}, {"name": "clip", "type": "CLIP", "link": 30}, {"name": "lora_stack", "type": "LORA_STACK", "link": 26}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [22], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [24, 25], "shape": 3, "slot_index": 1}], "properties": {"Node name for S&R": "CR Apply LoRA Stack"}}, {"id": 4, "type": "CLIPTextEncode", "pos": [1395, 451], "size": {"0": 400, "1": 200}, "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 25}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [6], "shape": 3}], "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["asian, (worst quality, low quality:1.4), (monochrome:1.3), 3d, text, frame, jpeg artifacts, grids, watermark, logo, username, text, particles, (missing fingers:1.3), bad hands, child, loli, animal ears, hat, headwear, umbrella, cropped, out of frame"]}, {"id": 5, "type": "KSampler", "pos": [1886, 98], "size": {"0": 315, "1": 262}, "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 22}, {"name": "positive", "type": "CONDITIONING", "link": 5}, {"name": "negative", "type": "CONDITIONING", "link": 6}, {"name": "latent_image", "type": "LATENT", "link": 7}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [9], "shape": 3}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [889447579184328, "randomize", 28, 7, "ddim", "normal", 1]}, {"id": 7, "type": "VAEDecode", "pos": [1979, 433], "size": {"0": 210, "1": 46}, "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 9}, {"name": "vae", "type": "VAE", "link": 10}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [8], "shape": 3}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 3, "type": "CLIPTextEncode", "pos": [1395, 200], "size": {"0": 400, "1": 200}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 24}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [5], "shape": 3}], "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["masterpiece, best quality, hyperrealistic, fine art painting of 1woman, (gatowsky) Mexican, medium closeup portrait, beautiful detailed eyes, perfect face, beautiful detailed face, looking at viewer, from below, amazing sharp focus, ultra detailed, soft skin,\nmedium black wavy hair, brown eyes, intricate crop top,  moaning, floating particles, aquatic atmosphere,  field,  medium breasts <hypernet:By bad artist -neg:1>  gigantic breats"]}, {"id": 17, "type": "LoRA Stacker", "pos": [948, 289], "size": {"0": 315, "1": 322}, "flags": {}, "order": 2, "mode": 0, "inputs": [{"name": "lora_stack", "type": "LORA_STACK", "link": null}], "outputs": [{"name": "LORA_STACK", "type": "LORA_STACK", "links": [26], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "LoRA Stacker"}, "widgets_values": ["simple", 5, "hipoly3DModelLora_v20.safetensors", 0.3, 1, 1, "GATOWSKY.pt", 1, 1, 1, "pokies.safetensors", 1, 1, 1, "wetshirtLora_v11.safetensors", 0.6, 1, 1, "more_details.safetensors", 0.3, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1, "None", 1, 1, 1], "color": "#222233", "bgcolor": "#333355", "shape": 1}, {"id": 9, "type": "SaveImage", "pos": [2310, 67], "size": [462.9618201171879, 413.52918403320336], "flags": {}, "order": 14, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 8}], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 18, "type": "IPAdapterModelLoader", "pos": [207.83934506503007, 762.5321363969277], "size": {"0": 315, "1": 58}, "flags": {}, "order": 3, "mode": 0, "outputs": [{"name": "IPADAPTER", "type": "IPADAPTER", "links": [31], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "IPAdapterModelLoader"}, "widgets_values": ["ip-adapter_sd15_light.bin"]}, {"id": 22, "type": "LoadImage", "pos": [195, 884], "size": [315, 314.0000228881836], "flags": {}, "order": 4, "mode": 0, "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [32], "shape": 3, "slot_index": 0}, {"name": "MASK", "type": "MASK", "links": null, "shape": 3}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["00025-1339700763.jpeg", "image"]}, {"id": 1, "type": "CheckpointLoaderSimple", "pos": [100, 130], "size": {"0": 315, "1": 98}, "flags": {}, "order": 5, "mode": 0, "outputs": [{"name": "MODEL", "type": "MODEL", "links": [33], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [1], "shape": 3}, {"name": "VAE", "type": "VAE", "links": null, "shape": 3}], "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "widgets_values": ["2   NSFW\\frankenstein_v2.safetensors"]}, {"id": 19, "type": "IPAdapterApply", "pos": [568, 609], "size": {"0": 315, "1": 258}, "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "ipadapter", "type": "IPADAPTER", "link": 31}, {"name": "clip_vision", "type": "CLIP_VISION", "link": 35}, {"name": "image", "type": "IMAGE", "link": 32}, {"name": "model", "type": "MODEL", "link": 33}, {"name": "attn_mask", "type": "MASK", "link": null}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [34], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "IPAdapterApply"}, "widgets_values": [0.6, 0, "original", 0, 1, false]}, {"id": 23, "type": "CLIPVisionLoader", "pos": [174, 659], "size": {"0": 315, "1": 58}, "flags": {}, "order": 6, "mode": 0, "outputs": [{"name": "CLIP_VISION", "type": "CLIP_VISION", "links": [35], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "CLIPVisionLoader"}, "widgets_values": ["SD1.5\\pytorch_model.bin"]}], "links": [[1, 1, 1, 2, 0, "CLIP"], [5, 3, 0, 5, 1, "CONDITIONING"], [6, 4, 0, 5, 2, "CONDITIONING"], [7, 6, 0, 5, 3, "LATENT"], [8, 7, 0, 9, 0, "IMAGE"], [9, 5, 0, 7, 0, "LATENT"], [10, 8, 0, 7, 1, "VAE"], [22, 14, 0, 5, 0, "MODEL"], [24, 14, 1, 3, 0, "CLIP"], [25, 14, 1, 4, 0, "CLIP"], [26, 17, 0, 14, 2, "LORA_STACK"], [30, 2, 0, 14, 1, "CLIP"], [31, 18, 0, 19, 0, "IPADAPTER"], [32, 22, 0, 19, 2, "IMAGE"], [33, 1, 0, 19, 3, "MODEL"], [34, 19, 0, 14, 0, "MODEL"], [35, 23, 0, 19, 1, "CLIP_VISION"]], "groups": [], "config": {}, "extra": {}, "version": 0.4}